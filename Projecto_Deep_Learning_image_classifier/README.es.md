<!-- hide -->
# RNA para clasificaciÃ³n de imÃ¡genes - GuÃ­a paso a paso
<!-- endhide -->

- Comprender un dataset nuevo.
- Modelar los datos utilizando una RNA.
- Analizar los resultados y optimizar el modelo.

## ğŸŒ± CÃ³mo iniciar este proyecto

Sigue las siguientes instrucciones:

1. Crea un nuevo repositorio basado en el [proyecto de Machine Learning](https://github.com/4GeeksAcademy/machine-learning-python-template) o [haciendo clic aquÃ­](https://github.com/4GeeksAcademy/machine-learning-python-template/generate).
2. Abre el repositorio creado recientemente en Codespace usando la [extensiÃ³n del botÃ³n de Codespace](https://docs.github.com/en/codespaces/developing-in-codespaces/creating-a-codespace-for-a-repository#creating-a-codespace-for-a-repository).
3. Una vez que el VSCode del Codespace haya terminado de abrirse, comienza tu proyecto siguiendo las instrucciones a continuaciÃ³n.

## ğŸš› CÃ³mo entregar este proyecto

Una vez que hayas terminado de resolver el caso prÃ¡ctico, asegÃºrate de confirmar tus cambios, haz push a tu repositorio y ve a 4Geeks.com para subir el enlace del repositorio.

## ğŸ“ Instrucciones

### Sistema de clasificaciÃ³n de imÃ¡genes

El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de uno mucho mÃ¡s grande de 3 millones de fotos anotadas manualmente. Estos datos se obtuvieron a travÃ©s de una colaboraciÃ³n entre Petfinder.com y Microsoft.

El conjunto de datos se usÃ³ originalmente como un CAPTCHA, es decir, una tarea que se cree que un humano encuentra trivial, pero que una mÃ¡quina no puede resolver, que se usa en sitios web para distinguir entre usuarios humanos y bots. La tarea se denominÃ³ "Asirra". Cuando se presentÃ³ "Asirra", se mencionÃ³ "que los estudios de usuarios indican que los humanos pueden resolverlo el 99,6% de las veces en menos de 30 segundos". A menos que se produzca un gran avance en la visiÃ³n artificial, esperamos que los ordenadores no tengan mÃ¡s de 1/54.000 posibilidades de resolverlo.

En el momento en que se publicÃ³ la competencia, el resultado de Ãºltima generaciÃ³n se logrÃ³ con un SVM y se describiÃ³ en un artÃ­culo de 2007 con el tÃ­tulo "Ataques de Machine Learning contra el CAPTCHA de Asirra" (PDF) que logrÃ³ una precisiÃ³n de clasificaciÃ³n del 80%. Fue este documento el que demostrÃ³ que la tarea ya no era una tarea adecuada para un CAPTCHA poco despuÃ©s de que se propusiera la tarea.

#### Paso 1: Carga del conjunto de datos

El conjunto de datos se encuentra en Kaggle y tendrÃ¡s que acceder a ella para descargarlos. La competiciÃ³n la puedes encontrar [aquÃ­](https://www.kaggle.com/c/dogs-vs-cats/data) (o copiando y pegando el siguiente enlace en tu navegador: `https://www.kaggle.com/c/dogs-vs-cats/data`)

Descarga la carpeta dataset y descomprime los archivos. Ahora tendrÃ¡s una carpeta llamada `train` que contiene 25.000 archivos de imagen (formato .jpg) de perros y gatos. Las fotos estÃ¡n etiquetadas por su nombre de archivo, con la palabra `dog` o `cat`.

#### Paso 2: Visualiza la informaciÃ³n de entrada

El primer paso cuando nos enfrentamos a un problema de clasificaciÃ³n de imÃ¡genes es obtener toda la informaciÃ³n posible a travÃ©s de ellas. Por lo tanto, carga e imprime las primeras nueve fotos de perros en una sola figura. Repite lo mismo para los gatos. Puedes ver que las fotos son a color y tienen diferentes formas y tamaÃ±os.

Esta variedad de tamaÃ±os y formatos debe solucionarse antes de entrenar el modelo. AsegÃºrate de que todas tengan un tamaÃ±o fijo de 200x200 pÃ­xeles.

Como podrÃ¡s ver, son una gran cantidad de imÃ¡genes, asegÃºrate de seguir las siguientes normas:

1. **Si tienes mÃ¡s de 12 gigabytes de RAM**, usa la API de procesamiento de imÃ¡genes de Keras para cargar las 25.000 fotos en el conjunto de datos de entrenamiento y remodelarlas a fotos cuadradas de 200Ã—200 pÃ­xeles. La etiqueta tambiÃ©n debe determinarse para cada foto en funciÃ³n de los nombres de archivo. Se debe guardar una tupla de fotos y etiquetas.
2. **Si no tienes mÃ¡s de 12 gigabytes de RAM**, carga las imÃ¡genes progresivamente usando la clase Keras `ImageDataGenerator` y la funciÃ³n `flow_from_directory()`. Esto serÃ¡ mÃ¡s lento de ejecutar, pero se ejecutarÃ¡ en hardware de menor capacidad. Esta funciÃ³n prefiere que los datos se dividan en directorios *train* y *test* separados, y debajo de cada directorio para tener un subdirectorio para cada clase.

Una vez tengas todas las imÃ¡genes procesadas, crea un objeto `ImageDataGenerator` para datos de entrenamiento y prueba. Luego pasa la carpeta que tiene datos de entrenamiento al objeto `trdata` y, de manera similar, pasa la carpeta que tiene datos de prueba al objeto `tsdata`. De esta forma, se etiquetarÃ¡n las imÃ¡genes automÃ¡ticamente y estarÃ¡ todo listo para entrar a la red.

#### Paso 3: Construye una RNA

Cualquier clasificador que se ajuste a este problema tendrÃ¡ que ser robusto porque algunas imÃ¡genes muestran al gato o al perro en una esquina o tal vez a 2 gatos o perros en la misma foto. Si has podido investigar algunas de las implementaciones de los ganadores de otras competiciones tambiÃ©n relacionadas con imÃ¡genes, verÃ¡s que `VGG16` es una arquitectura de CNN utilizada para ganar la competencia de Kaggle ILSVR (Imagenet) en 2014. Se considera una de las arquitecturas de modelos de visiÃ³n con mejores resultados hasta la fecha.

Utiliza la siguiente arquitectura de prueba:

```py
model = Sequential()
model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Flatten())
model.add(Dense(units = 4096,activation = "relu"))
model.add(Dense(units = 4096,activation = "relu"))
model.add(Dense(units = 2, activation = "softmax"))
```

El cÃ³digo anterior aplica convoluciones a los datos (capas `Conv2D` y `MaxPool2D`) y despuÃ©s aplica capas densas (capas `Dense`) para el procesamiento de los valores numÃ©ricos obtenidos tras las convoluciones.

A continuaciÃ³n aÃ±ade los elementos restantes para conformar el modelo, entrÃ©nalo y mide su rendimiento.

#### Paso 4: Optimiza el modelo anterior

Importa el mÃ©todo `ModelCheckpoint` y `EarlyStopping` de Keras. Crea un objeto de ambos y pÃ¡salo como funciones callback a `fit_generator`.

Carga el mejor modelo de los anteriores y utiliza el conjunto de test para hacer predicciones.

#### Paso 5: Guarda el modelo

Almacena el modelo en la carpeta correspondiente.

> Nota: TambiÃ©n incorporamos muestras de soluciÃ³n en `./solution.ipynb` que te sugerimos honestamente que solo uses si estÃ¡s atascado por mÃ¡s de 30 minutos o si ya has terminado y quieres compararlo con tu enfoque.

---

## âœ… Proyecto Personal / ImplementaciÃ³n Final

> *A continuaciÃ³n se presenta el resumen de la implementaciÃ³n propia desarrollada por Valentina LarraÃ±aga.*

### ğŸ“ Estructura del proyecto

Este proyecto estÃ¡ organizado en **dos notebooks**:

1. `01_data_preparation.ipynb`: descarga y preprocesamiento del dataset.
2. `02_model_training.ipynb`: definiciÃ³n del modelo, entrenamiento y evaluaciÃ³n.

### âš ï¸ Consideraciones tÃ©cnicas

- Debido a limitaciones de hardware (RAM reducida), el tamaÃ±o del dataset se redujo temporalmente a 10 imÃ¡genes para entrenamiento y validaciÃ³n.
- Esto afecta la estabilidad de las mÃ©tricas y los grÃ¡ficos, pero permite validar el flujo completo del modelo en entornos limitados.

### ğŸ§  Modelo utilizado

Se empleÃ³ una CNN inspirada en VGG, con capas `Conv2D`, `MaxPool2D` y `Dense`, finalizando con una neurona de salida y activaciÃ³n `sigmoid` para clasificaciÃ³n binaria.

El entrenamiento se complementÃ³ con:

- `ModelCheckpoint`: guarda el mejor modelo durante el entrenamiento.
- `EarlyStopping`: detiene el entrenamiento si no hay mejora.

### ğŸ“‰ Resultados

El entrenamiento mostrÃ³ comportamiento inestable en las mÃ©tricas debido al tamaÃ±o reducido de los datos, pero confirmÃ³ el correcto funcionamiento del flujo de carga, entrenamiento, evaluaciÃ³n y predicciÃ³n.

### ğŸ§ª PredicciÃ³n

Se realizÃ³ una prueba de predicciÃ³n sobre una imagen individual, con el modelo previamente guardado (`mejor_modelo.keras`), obteniendo la probabilidad de que fuera un gato o un perro.

---

## ğŸ“¬ Contacto

Proyecto desarrollado por Valentina LarraÃ±aga.  
ğŸ“§ mvlarra@outlook.com  
ğŸŒ [LinkedIn](https://www.linkedin.com/)